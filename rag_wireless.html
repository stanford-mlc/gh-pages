<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Meta Thinking LLMs</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Source+Serif+4:400,600,700|Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    body {
      font-family: 'Source Serif 4', serif;
    }
  </style>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-3 publication-title">Retrieval Augmented Generation with Multi-Modal LLM Framework for Wireless Environments</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://ahmd-mohsin.github.io/" target="_blank">Muhammad Ahmed Mohsin</a><sup>1*</sup>,
              </span>
              <span class="author-block">
                <a href="https://ahsanbilal7.github.io/" target="_blank">Ahsan Bilal</a><sup>2*</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=xNb5T5IAAAAJ" target="_blank">Sagnik
                  Bhattacharya</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://cioffi-group.stanford.edu/" target="_blank">John M. Cioffi</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup>Stanford University, <sup>2</sup>University of Oklahoma
                <br>
                <sup>*</sup>Equal Contribution
                <br>
                International Conference on Communications 2025 Workshop
                <br>
                <span style="color: red; font-weight: bold;">ðŸŽ‰Best Workshop Paper Award ðŸŽ‰</span>
              </span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2503.07670" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2503.07670" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://github.com/AhsanBilal7/Retrieval-augmented-generation-with-multi-modal-llm-framework-for-wireless-environments"
                    target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>


              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- End teaser video -->
  <div class="container is-max-desktop">
    <div class="hero-body">
        <h2 class="title has-text-centered">Proposed Framework</h2>
      <img src="static/rag_wireless/flow_chart.png" alt="RAG Wireless Flow Chart"
        style="width:100%;" />
      <h2 class="subtitle has-text-centered">
      Work flow for vector database creation for RAG-based LLM wireless environment perception
      </h2>
    </div>
  </div>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
            Future wireless networks aims to deliver high data rates and lower power consumption while ensuring seamless connectivity, necessitating robust wireless network optimization. To achieve this, wireless network optimization is necessary. Large language models (LLMs) have been deployed for generalized optimization scenarios. To take advantage of generative AI (GAI) models, retrieval augmented generation (RAG) is proposed for multi-sensor wireless environment perception. Utilizing domainspecific prompt engineering, we apply retrieval-augmented generation (RAG) to efficiently harness multimodal data inputs from sensors in a wireless environment. Wireless environment perception is necessary for global LLM optimization tasks. Key pre-processing pipelines including image-to-text conversion, object detection, and distance calculations for multimodal RAG input from multi-sensor data from different devices are proposed in this paper to obtain a unified vector database crucial for optimizing large language models (LLMs) in global wireless tasks. Our evaluation, conducted with OpenAIâ€™s GPT and Googleâ€™s Gemini models, demonstrates an 8%, 8%, 10%, 7%, and 12% improvement in relevancy, faithfulness, completeness, similarity, and accuracy, respectively, compared to conventional LLM-based designs. Furthermore, our RAG-based LLM framework with vectorized databases are computationally efficient providing real time convergence under latency constraints
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- Image carousel -->
  <section class="section hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 is is-centered">Results</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static/rag_wireless/comparison.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              A detailed response comparison for RAG-based LLM vs. Vanilla LLM [baseline]
              <!-- Caption -->
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/rag_wireless/results.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
            (a) Correctness, (b) Faithfulness, (c) Similarity: RAG-based vs. baseline LLMs [0-1].
              <!-- Caption -->
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->




  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{mohsin2025retrieval,
        title={Retrieval augmented generation with multi-modal llm framework for wireless environments},
        author={Mohsin, Muhammad Ahmed and Bilal, Ahsan and Bhattacharya, Sagnik and Cioffi, John M},
        journal={arXiv preprint arXiv:2503.07670},
        year={2025}}</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->

  <script>

    fetch('footer.html')
      .then(response => response.text())
      .then(html => {
        document.getElementById('footer-container').innerHTML = html;
      });
  </script>
  <div id="footer-container"></div>


</body>

</html>